{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0272da2b",
   "metadata": {},
   "source": [
    "# PyTorch for Deep Learning & Machine Learning – Full Course\n",
    "\n",
    "PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella. \n",
    "\n",
    "**Video link**:[PyTorch for Deep Learning & Machine Learning – Full Course](https://youtu.be/V_xro1bcAuA)\n",
    "\n",
    "**Reference link**:[Pytorch Docs](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "## General Parts\n",
    "\n",
    "|Serial Number|Title|TimeStamp|\n",
    "|:-------------:|:-----:|:---:|\n",
    "|1| PyTorch Fundamentals |[0:01:45](https://www.youtube.com/watch?v=V_xro1bcAuA&t=105s)|\n",
    "|2|PyTorch Workflow|[4:17:27](https://www.youtube.com/watch?v=V_xro1bcAuA&t=15447s)|\n",
    "|3|Neural Network Classification|[8:32:00](https://www.youtube.com/watch?v=V_xro1bcAuA&t=30720s)|\n",
    "|4|Computer Vision|[14:00:48](https://www.youtube.com/watch?v=V_xro1bcAuA&t=50448s)|\n",
    "|5|Custom Datasets|[19:44:05](https://www.youtube.com/watch?v=V_xro1bcAuA&t=71045s)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f737a0",
   "metadata": {},
   "source": [
    "## Check List \n",
    "\n",
    "- [ ] PyTorch Fundamentals\n",
    "- [ ] PyTorch Workflow\n",
    "- [ ] Neural Network Classification \t\n",
    "- [ ] Computer Vision\n",
    "- [ ] Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73623f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078ed058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct  2 21:53:41 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.42                 Driver Version: 537.42       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   36C    P3              14W /  40W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc32331",
   "metadata": {},
   "source": [
    "# Introduction to Tensors\n",
    "\n",
    "![Difference between](https://res.cloudinary.com/practicaldev/image/fetch/s--oTgfo1EL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://raw.githubusercontent.com/adhiraiyan/DeepLearningWithTF2.0/master/notebooks/figures/fig0201a.png)  \n",
    "\n",
    "## Scalar\n",
    "\n",
    "<mark>A scalar is an element of a field which is used to define a vector space</mark>. In linear algebra, real numbers or generally elements of a field are called scalars and relate to vectors in an associated vector space through the operation of scalar multiplication (defined in the vector space), in which a vector can be multiplied by a scalar in the defined way to produce another vector.\n",
    "\n",
    "## Vector\n",
    "\n",
    "<mark>A vector is an object that has both a magnitude and a direction.</mark> Geometrically, we can picture a vector as a directed line segment, whose length is the magnitude of the vector and with an arrow indicating the direction. The direction of the vector is from its tail to its head.\n",
    "\n",
    "![Vector](https://mathinsight.org/media/image/image/vector.png)\n",
    "\n",
    "## Tensor\n",
    "\n",
    "In mathematics, <mark>a tensor is an algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space</mark>. Tensors may map between different objects such as vectors, scalars, and even other tensors. There are many types of tensors, including scalars and vectors (which are the simplest tensors), dual vectors, multilinear maps between vector spaces, and even some operations such as the dot product. Tensors are defined independent of any basis, although they are often referred to by their components in a basis related to a particular coordinate system. \n",
    "\n",
    "A [Tensor](https://pytorch.org/docs/stable/tensors.html#torch-tensor) is a multi-dimensional matrix containing elements of a single data type.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Components_stress_tensor.svg/1200px-Components_stress_tensor.svg.png\"  width=\"40%\" height=\"20%\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cdebf9",
   "metadata": {},
   "source": [
    "## Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072c06c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6027580",
   "metadata": {},
   "source": [
    "## Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20fad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b686a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac0a682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6d2cb",
   "metadata": {},
   "source": [
    "## Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caaf7858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7,8],\n",
    "                      [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a85a53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b88c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71eac44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68cb039f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1fac8",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411fafc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                       [3,6,9],\n",
    "                       [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fff27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dee9528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f556a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e44acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b548d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38bb9d",
   "metadata": {},
   "source": [
    "# Functions to inspect Tensors\n",
    "\n",
    "## ndim\n",
    "\n",
    "[ndim](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html) returns the number of dimensions of self tensor.\n",
    "\n",
    "## item\n",
    "\n",
    "[item](https://pytorch.org/docs/stable/generated/torch.Tensor.item.html) Returns the value of this tensor as a standard Python number. This only works for tensors with one element.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f38bc",
   "metadata": {},
   "source": [
    "## ndim\n",
    "\n",
    "`ndim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee42386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1101b8",
   "metadata": {},
   "source": [
    "## item\n",
    "\n",
    "return as normal number\n",
    "\n",
    "`item()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4afec62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa1071",
   "metadata": {},
   "source": [
    "# Random tensors\n",
    "\n",
    "[rand](https://pytorch.org/docs/stable/generated/torch.rand.html) Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1).The shape of the tensor is defined by the variable argument size.\n",
    "\n",
    "`rand( rows, columns)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54f99204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1052, 0.3494, 0.5413, 0.5497],\n",
       "         [0.3112, 0.7992, 0.4034, 0.6083],\n",
       "         [0.8822, 0.9763, 0.5735, 0.8590]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(1,3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "364a5c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d910f4",
   "metadata": {},
   "source": [
    "# Image in tensor\n",
    "\n",
    "For example, you could represent an image as a tensor with shape [3, 224, 224] which would mean [colour_channels, height, width], as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels.\n",
    "\n",
    "![imageTensor](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5408591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d1268",
   "metadata": {},
   "source": [
    "## Creating Tensors of zero and one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4352d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = torch.zeros(3,4)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9e2045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero*random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "972a3370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = torch.ones(3,4)\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3eb29d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43032084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a9766",
   "metadata": {},
   "source": [
    "## creating range of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbf09d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start = 1, end = 11, step = 1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0b25e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zero = torch.zeros_like(one_to_ten)\n",
    "ten_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814408c1",
   "metadata": {},
   "source": [
    "## Tensor DataType\n",
    "\n",
    "**dtype** is datatype in tensor [e.g](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "Common errors\n",
    "\n",
    "- Tensors not right datatype\n",
    "- Tensors not right shape\n",
    "- Tensors not on the right device\n",
    "\n",
    "**device** is what type your device is on cpu or cuda(GPU)\n",
    "\n",
    "**requires_grad** whether or not to track gradient with this tensors operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e0953df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=None,device=None,requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39bcd4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df0bddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.half)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c42d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb574bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de9b96ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "571f891f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LongTensor_tensor = torch.tensor([3,6,9], dtype=torch.long)\n",
    "LongTensor_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2b62ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * LongTensor_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e04ba0",
   "metadata": {},
   "source": [
    "## Trouble Shooting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b62c6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2060, 0.1958, 0.5826, 0.3064],\n",
       "        [0.0073, 0.3870, 0.7352, 0.9600],\n",
       "        [0.8751, 0.0473, 0.4399, 0.0502]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3159fc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2060, 0.1958, 0.5826, 0.3064],\n",
      "        [0.0073, 0.3870, 0.7352, 0.9600],\n",
      "        [0.8751, 0.0473, 0.4399, 0.0502]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b92feca",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (tensor Operations)\n",
    "\n",
    "Tensor Operations include:\n",
    "- Addition\n",
    "- Subtraction\n",
    "- Multiplication\n",
    "- Division\n",
    "- Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdb51c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 102, 103])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ad5eb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be7c7039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "567ef930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39173d8",
   "metadata": {},
   "source": [
    "## Inbuilt Function\n",
    "\n",
    "- mul\n",
    "- add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd588017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "430b026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec013c4",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "Two ways of performing multiplication in neural networks and deep learning:\n",
    "\n",
    "1. Element wise multiplication\n",
    "2. Matrix multiplication (dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2c042ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f885d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print( tensor, \"*\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5545e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Equals: {tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38387406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8d9e6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 1 + 2 * 2 + 3* 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8c548",
   "metadata": {},
   "source": [
    "## torch function faster than for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cbb16c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value+= tensor[i]*tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a13e60f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab9a1bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3837ae2",
   "metadata": {},
   "source": [
    "## Shape errors\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "\n",
    "1. the **inner dimensions** must match:\n",
    "* ` (3,2) @ (3,2) ` won't work\n",
    "* ` (2,3) @ (3,2) ` will work\n",
    "* ` (3,2) @ (2,3) ` will work\n",
    "\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2,3) @ (3,2)` -> `(2,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1c38344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1503, 0.3969, 0.3718],\n",
       "        [0.2312, 0.9988, 1.0083],\n",
       "        [0.8165, 0.9542, 0.6689]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(3,2),torch.rand(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a00a1026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                        [8,11],\n",
    "                        [9,12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646e73b",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues we can fix by manipulating the shape using transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b92563d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21f5291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [ 8, 11],\n",
       "        [ 9, 12]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1985936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying : torch.Size([3, 2]) @ torch.Size([3, 2]) <- inner dimesions must match\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying : {tensor_A.shape} @ {tensor_B.shape} <- inner dimesions must match\")\n",
    "\n",
    "output = torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e9c25",
   "metadata": {},
   "source": [
    "## Finding Min, Max, mean, sum (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2a0f117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b397d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc923bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa0a49",
   "metadata": {},
   "source": [
    "Find the mean function requires a tensor of float32 datatype to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0c5ea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a479abca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc1a9e",
   "metadata": {},
   "source": [
    "## Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3cf51e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2568c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin() #returns position of minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa80d297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edb854f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edceab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c262879",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeezing and Unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* stacking - Concatenates a sequence of tensors along a new dimension\n",
    "* squeezing - Returns a tensor with all specified dimensions of input of size 1 removed\n",
    "* unsqueezing - Returns a new tensor with a dimension of size one inserted at the specified position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe31e318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ecb57",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "\n",
    "Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df507592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(3,3)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3fcf7",
   "metadata": {},
   "source": [
    "## view\n",
    "\n",
    "view only shows does not actually alter the shape unlike reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1b7b461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed113d",
   "metadata": {},
   "source": [
    "## stack\n",
    "\n",
    "* vstack - 1 dimension\n",
    "* hstack - 0 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c08d07c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x ,x ,x , x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f68b59",
   "metadata": {},
   "source": [
    "## squeeze\n",
    "\n",
    "Returns a tensor with all specified dimensions of input of size 1 removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a984b3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2fe9d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.squeeze(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173cb40e",
   "metadata": {},
   "source": [
    "## unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55684a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.unsqueeze(y,1)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f009c0",
   "metadata": {},
   "source": [
    "## permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25be6ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "x.size()\n",
    "torch.permute(x, (2, 0, 1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ef2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "pyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
